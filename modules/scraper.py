"""
Ù…Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø²ÙˆÙ„ - ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Termux
"""

import requests
from bs4 import BeautifulSoup
import json
import time

class SudanScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Android 13; Mobile) AppleWebKit/537.36'
        })
    
    def search(self, query, location='Ø§Ù„Ø³ÙˆØ¯Ø§Ù†', limit=10):
        """Ø¨Ø­Ø« Ø¹Ù† Ø¹Ø±ÙˆØ¶"""
        print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query} ÙÙŠ {location}")
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        results = []
        
        for i in range(min(limit, 5)):
            result = {
                'id': i + 1,
                'title': f'{query} ÙÙŠ {location} - Ø¹Ø±Ø¶ {i+1}',
                'description': f'ÙˆØµÙ {query} ÙÙŠ {location}. Ù‡Ø°Ø§ Ø¹Ø±Ø¶ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ø²ÙˆÙ„.',
                'price': f'{i+1},000,000 Ø¬Ù†ÙŠÙ‡' if 'Ø¹Ù‚Ø§Ø±' in query else f'{i+1}00,000 Ø¬Ù†ÙŠÙ‡',
                'location': location,
                'category': 'real_estate' if 'Ø¹Ù‚Ø§Ø±' in query or 'Ø´Ù‚Ø©' in query else 'general',
                'contact': f'09{i+1}2345678',
                'features': {
                    'Ø§Ù„Ø­Ø§Ù„Ø©': 'Ø¬Ø¯ÙŠØ¯',
                    'Ø§Ù„ØªÙˆÙØ±': 'Ù…Ø¨Ø§Ø´Ø±'
                },
                'date': '2024-01-15'
            }
            results.append(result)
        
        return results
    
    def fetch_from_file(self, filename):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù Ù…Ø­Ù„ÙŠ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    
    def save_to_file(self, data, filename):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except:
            return False

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙˆØ­Ø¯Ø©
if __name__ == '__main__':
    scraper = SudanScraper()
    results = scraper.search('Ø´Ù‚Ø© Ù„Ù„Ø¥ÙŠØ¬Ø§Ø±', 'Ø§Ù„Ø®Ø±Ø·ÙˆÙ…', 3)
    print(f"âœ… ØªÙ… Ø¬Ù…Ø¹ {len(results)} Ù†ØªÙŠØ¬Ø©")
